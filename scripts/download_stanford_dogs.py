#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Stanford Dogs –¥–∞—Ç–∞—Å–µ—Ç–∞
"""

import os
import requests
import zipfile
import shutil
from pathlib import Path
import random
from PIL import Image
import json
from tqdm import tqdm
import torchvision.transforms as transforms

def download_file(url, filename):
    """–°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º"""
    print(f"–°–∫–∞—á–∏–≤–∞–µ–º {filename}...")
    response = requests.get(url, stream=True)
    total_size = int(response.headers.get('content-length', 0))
    
    with open(filename, 'wb') as file, tqdm(
        desc=filename,
        total=total_size,
        unit='iB',
        unit_scale=True,
        unit_divisor=1024,
    ) as progress_bar:
        for chunk in response.iter_content(chunk_size=8192):
            size = file.write(chunk)
            progress_bar.update(size)
    
    print(f"‚úÖ {filename} —Å–∫–∞—á–∞–Ω —É—Å–ø–µ—à–Ω–æ!")

def download_stanford_dogs():
    """–°–∫–∞—á–∞—Ç—å Stanford Dogs –¥–∞—Ç–∞—Å–µ—Ç"""
    data_dir = Path("data/stanford_dogs")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    # URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è Stanford Dogs
    url = "http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar"
    archive_path = data_dir / "images.tar"
    
    if not archive_path.exists():
        download_file(url, str(archive_path))
    
    # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –∞—Ä—Ö–∏–≤
    extract_dir = data_dir / "extracted"
    if not extract_dir.exists():
        print("–†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –∞—Ä—Ö–∏–≤...")
        os.system(f"cd {data_dir} && tar -xf images.tar")
        print("‚úÖ –ê—Ä—Ö–∏–≤ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω!")
    
    return data_dir

def create_fan_dataset(data_dir, max_samples_per_class=15):
    """–°–æ–∑–¥–∞—Ç—å FAN –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ Stanford Dogs"""
    print("–°–æ–∑–¥–∞–µ–º FAN –¥–∞—Ç–∞—Å–µ—Ç...")
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
    fan_dir = Path("data/stanford_dogs_fan")
    fan_dir.mkdir(parents=True, exist_ok=True)
    img_dir = fan_dir / "img"
    img_dir.mkdir(exist_ok=True)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
    images_dir = data_dir / "Images"
    if not images_dir.exists():
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–∞–ø–∫—É —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        for subdir in data_dir.iterdir():
            if subdir.is_dir() and "Images" in subdir.name:
                images_dir = subdir
                break
    
    if not images_dir.exists():
        raise FileNotFoundError("–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏!")
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–ª–∞—Å—Å—ã
    all_classes = [d.name for d in images_dir.iterdir() if d.is_dir()]
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(all_classes)} –∫–ª–∞—Å—Å–æ–≤")
    
    # –í—ã–±–∏—Ä–∞–µ–º 20 —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è FAN –¥–∞—Ç–∞—Å–µ—Ç–∞
    selected_classes = random.sample(all_classes, min(20, len(all_classes)))
    print(f"–í—ã–±—Ä–∞–Ω–æ {len(selected_classes)} –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è FAN –¥–∞—Ç–∞—Å–µ—Ç–∞")
    
    # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    entries = []
    class_names = []
    
    for class_idx, class_name in enumerate(selected_classes):
        class_dir = images_dir / class_name
        if not class_dir.exists():
            continue
            
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–ª–∞—Å—Å–µ
        image_files = list(class_dir.glob("*.jpg")) + list(class_dir.glob("*.jpeg")) + list(class_dir.glob("*.png"))
        
        # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        selected_images = random.sample(image_files, min(max_samples_per_class, len(image_files)))
        
        class_names.append(class_name.replace("_", " ").title())
        
        for img_file in selected_images:
            # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            new_img_name = f"{class_idx:03d}_{img_file.stem}.jpg"
            new_img_path = img_dir / new_img_name
            
            # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ JPG
            try:
                with Image.open(img_file) as img:
                    img = img.convert('RGB')
                    img.save(new_img_path, 'JPEG', quality=95)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {img_file}: {e}")
                continue
            
            # –°–æ–∑–¥–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            description = f"A photo of a {class_name.replace('_', ' ')} dog"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å
            entries.append({
                'img': f'img/{new_img_name}',
                'text': description,
                'label': class_idx,
                'class_name': class_names[-1]
            })
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    with open(fan_dir / "train.jsonl", 'w', encoding='utf-8') as f:
        for entry in entries:
            f.write(json.dumps(entry, ensure_ascii=False) + '\n')
    
    # –°–æ–∑–¥–∞–µ–º dataset_info.json
    dataset_info = {
        "name": "Stanford Dogs FAN Subset",
        "description": "Subset of Stanford Dogs dataset adapted for Fuzzy Attention Networks",
        "total_samples": len(entries),
        "classes": class_names,
        "samples_per_class": max_samples_per_class,
        "image_size": "224x224",
        "source": "Stanford Dogs (http://vision.stanford.edu/aditya86/ImageNetDogs/)",
        "license": "Academic Use",
        "created_for": "Fuzzy Attention Networks research"
    }
    
    with open(fan_dir / "dataset_info.json", 'w', encoding='utf-8') as f:
        json.dump(dataset_info, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ FAN –¥–∞—Ç–∞—Å–µ—Ç —Å–æ–∑–¥–∞–Ω!")
    print(f"üìä –í—Å–µ–≥–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(entries)}")
    print(f"üìä –ö–ª–∞—Å—Å–æ–≤: {len(class_names)}")
    print(f"üìä –û–±—Ä–∞–∑—Ü–æ–≤ –Ω–∞ –∫–ª–∞—Å—Å: {max_samples_per_class}")
    
    return fan_dir

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üêï –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ Stanford Dogs –¥–∞—Ç–∞—Å–µ—Ç–∞")
    print("=" * 50)
    
    # –°–∫–∞—á–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    data_dir = download_stanford_dogs()
    
    # –°–æ–∑–¥–∞–µ–º FAN –¥–∞—Ç–∞—Å–µ—Ç
    fan_dir = create_fan_dataset(data_dir, max_samples_per_class=15)
    
    print("\nüéâ –ì–æ—Ç–æ–≤–æ!")
    print(f"üìÅ FAN –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {fan_dir}")
    print("üöÄ –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ!")

if __name__ == "__main__":
    main()


