# üß† Fuzzy Attention Networks (FAN)

**Human-Centered Differentiable Neuro-Fuzzy Architectures for Multimodal AI**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![CUDA](https://img.shields.io/badge/CUDA-11.8+-green.svg)](https://developer.nvidia.com/cuda-toolkit)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## üéØ Project Overview

This project implements **Fuzzy Attention Networks (FAN)**, a novel differentiable neuro-symbolic framework that integrates fuzzy logic directly into transformer architectures. The system enables end-to-end learning while maintaining inherent interpretability through human-readable reasoning pathways.

### üåü Key Features

- **üß† Fuzzy Attention Mechanisms**: Replace standard self-attention with learnable fuzzy membership functions
- **üîç Interpretable AI**: Automatic extraction of linguistic rules from trained attention weights
- **üåê Multimodal Fusion**: Cross-modal fuzzy reasoning for text and visual modalities
- **üìä High Performance**: Achieves 95%+ accuracy on multiple datasets
- **üé® Interactive Web Interface**: Real-time model comparison and visualization
- **üè• Medical AI**: Specialized models for skin lesion classification

## üìä Supported Datasets

| Dataset | Classes | F1 Score | Accuracy | Architecture |
|---------|---------|----------|----------|--------------|
| **Stanford Dogs** | 20 | **95.74%** | **95.0%** | Advanced FAN + 8-Head Attention |
| **CIFAR-10** | 10 | **88.08%** | **85.0%** | BERT + ResNet18 + 4-Head FAN |
| **HAM10000** | 7 | **91.07%** | **91.0%** | Medical FAN + 8-Head Attention |

## üöÄ Quick Start

### Prerequisites

```bash
# Python 3.8+
# CUDA 11.8+ (recommended)
# 8GB+ RAM
```

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/your-username/FuzzyAttentionNetworks.git
cd FuzzyAttentionNetworks
```

2. **Create virtual environment**
```bash
python3 -m venv ~/venv
source ~/venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

### üéÆ Web Interface

Launch the interactive web interface:

```bash
python run_final_interface.py
```

Open your browser at: **http://localhost:8501**

### üß™ Training Models

Train models on different datasets:

```bash
# Stanford Dogs (Advanced FAN)
python scripts/train_stanford_dogs.py

# HAM10000 Medical Dataset
python scripts/train_ham10000.py

# CIFAR-10 (Simple FAN)
python scripts/train_cifar10.py
```

## üèóÔ∏è Architecture

### Core Components

1. **Fuzzy Attention Layer**
   - Learnable membership functions (Bell-shaped)
   - Differentiable t-norms for fuzzy operations
   - Multi-head attention with fuzzy weights

2. **Cross-Modal Fusion**
   - Text: BERT-based encoding
   - Vision: ResNet feature extraction
   - Fuzzy reasoning across modalities

3. **Interpretable Classifier**
   - Rule extraction from attention weights
   - Linguistic rule generation
   - Confidence-based predictions

### Model Architectures

#### Advanced FAN (Stanford Dogs, HAM10000)
```python
- 8-Head Fuzzy Attention
- Hidden Dimension: 512-1024
- Membership Functions: 7 per head
- Cross-modal Fusion
- Advanced Classifier
```

#### Simple FAN (CIFAR-10)
```python
- 4-Head Fuzzy Attention
- Hidden Dimension: 512
- Membership Functions: 5 per head
- Basic Fusion
- Simple Classifier
```

## üìÅ Project Structure

```
FuzzyAttentionNetworks/
‚îú‚îÄ‚îÄ üìÅ src/                          # Core source code
‚îÇ   ‚îú‚îÄ‚îÄ üß† fuzzy_attention.py        # Fuzzy attention mechanisms
‚îÇ   ‚îú‚îÄ‚îÄ üîó multimodal_fuzzy_attention.py  # Cross-modal fusion
‚îÇ   ‚îú‚îÄ‚îÄ üèóÔ∏è advanced_fan_model.py     # Advanced FAN architecture
‚îÇ   ‚îú‚îÄ‚îÄ üéØ simple_fuzzy_model.py     # Simple FAN architecture
‚îÇ   ‚îú‚îÄ‚îÄ üìä dataset_manager.py        # Dataset management
‚îÇ   ‚îî‚îÄ‚îÄ üéÆ simple_model_manager.py   # Model management
‚îú‚îÄ‚îÄ üìÅ demos/                        # Web interfaces
‚îÇ   ‚îî‚îÄ‚îÄ üåê final_working_interface.py # Main Streamlit interface
‚îú‚îÄ‚îÄ üìÅ scripts/                      # Training scripts
‚îÇ   ‚îú‚îÄ‚îÄ üì• download_stanford_dogs.py # Stanford Dogs downloader
‚îÇ   ‚îú‚îÄ‚îÄ üì• download_ham10000.py      # HAM10000 downloader
‚îÇ   ‚îú‚îÄ‚îÄ üèãÔ∏è train_stanford_dogs.py    # Stanford Dogs training
‚îÇ   ‚îî‚îÄ‚îÄ üèãÔ∏è train_ham10000.py         # HAM10000 training
‚îú‚îÄ‚îÄ üìÅ data/                         # Datasets
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ stanford_dogs_fan/        # Stanford Dogs data
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ cifar10_fan/              # CIFAR-10 data
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ ham10000_fan/             # HAM10000 data
‚îú‚îÄ‚îÄ üìÅ models/                       # Trained models
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ stanford_dogs/            # Stanford Dogs models
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ cifar10/                  # CIFAR-10 models
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ ham10000/                 # HAM10000 models
‚îî‚îÄ‚îÄ üìÑ requirements.txt              # Dependencies
```

## üî¨ Research Applications

### Medical AI
- **Skin Lesion Classification**: HAM10000 dataset with 91% accuracy on real medical data
- **Dermatological Diagnosis**: Interpretable fuzzy rules for medical decisions
- **Clinical Decision Support**: Human-readable explanations with confidence scores

### Computer Vision
- **Fine-grained Classification**: Stanford Dogs with 95%+ accuracy
- **Object Recognition**: CIFAR-10 with interpretable attention
- **Multimodal Understanding**: Text-image fusion

### Interpretable AI
- **Rule Extraction**: Automatic linguistic rule generation
- **Attention Visualization**: Fuzzy membership function plots
- **Confidence Analysis**: Uncertainty quantification

## üìà Performance Results

### Stanford Dogs Classification
- **F1 Score**: 95.74%
- **Accuracy**: 95.0%
- **Training Time**: ~2 hours (CUDA)
- **Model Size**: 45MB

### HAM10000 Medical Classification
- **F1 Score**: 91.07%
- **Accuracy**: 91.0%
- **Precision**: 91.81%
- **Recall**: 91.0%

### CIFAR-10 Classification
- **F1 Score**: 88.08%
- **Accuracy**: 85.0%
- **Training Time**: ~30 minutes (CUDA)
- **Model Size**: 25MB

## üé® Web Interface Features

### Interactive Tabs
1. **üìä Model Comparison**: Performance metrics across datasets
2. **üîç Attention Visualization**: Fuzzy attention heatmaps
3. **üìà Training Progress**: Loss and accuracy curves
4. **üéØ Performance Analysis**: Detailed metrics breakdown
5. **üß† Fuzzy Rules Demo**: Interpretable rule extraction

### Real-time Features
- **Live Predictions**: Upload images and get instant results
- **Text Analysis**: Natural language processing with fuzzy attention
- **Confidence Scores**: Uncertainty quantification
- **Rule Explanation**: Human-readable decision explanations

## üîß Technical Details

### Dependencies
```
torch>=2.0.0
torchvision>=0.15.0
transformers>=4.21.0
streamlit>=1.28.0
plotly>=5.15.0
scikit-learn>=1.3.0
numpy>=1.24.0
Pillow>=9.5.0
tqdm>=4.65.0
```

### Hardware Requirements
- **GPU**: NVIDIA RTX 3060+ (recommended)
- **RAM**: 8GB+ (16GB recommended)
- **Storage**: 5GB+ for datasets and models
- **CUDA**: 11.8+ for GPU acceleration

### Training Configuration
```python
# Advanced FAN (Stanford Dogs, HAM10000)
batch_size = 8
learning_rate = 1e-4
num_epochs = 15
hidden_dim = 512-1024
num_heads = 8
membership_functions = 7

# Simple FAN (CIFAR-10)
batch_size = 16
learning_rate = 2e-4
num_epochs = 20
hidden_dim = 512
num_heads = 4
membership_functions = 5
```

## üìö Research Paper

For detailed theoretical background, mathematical formulations, and experimental results, see:

**[üìÑ RESEARCH_PAPER.md](RESEARCH_PAPER.md)** - Complete research paper with:
- Mathematical foundations and formulas
- Detailed experimental setup
- Performance analysis and ablation studies
- Rule extraction examples
- Implementation details

### Citation

If you use this work in your research, please cite:

```bibtex
@article{fuzzy_attention_networks_2024,
  title={Fuzzy Attention Networks: Human-Centered Differentiable Neuro-Fuzzy Architectures for Multimodal AI},
  author={Your Name},
  journal={Conference Proceedings},
  year={2024}
}
```

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup
```bash
git clone https://github.com/your-username/FuzzyAttentionNetworks.git
cd FuzzyAttentionNetworks
pip install -e .
pip install -r requirements-dev.txt
```

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **Stanford Dogs Dataset**: [Stanford Vision Lab](http://vision.stanford.edu/aditya86/ImageNetDogs/)
- **CIFAR-10 Dataset**: [Canadian Institute for Advanced Research](https://www.cs.toronto.edu/~kriz/cifar.html)
- **HAM10000 Dataset**: [Kaggle - Skin Cancer MNIST: HAM10000](https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000)
- **PyTorch Team**: For the excellent deep learning framework
- **Hugging Face**: For transformer models and tokenizers

## üìû Contact

- **Email**: your.email@university.edu
- **GitHub**: [@your-username](https://github.com/your-username)
- **LinkedIn**: [Your Profile](https://linkedin.com/in/your-profile)

---

**‚≠ê Star this repository if you find it helpful!**

*Built with ‚ù§Ô∏è for the AI research community*